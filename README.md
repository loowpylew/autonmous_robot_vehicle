# autonmous_robot_vehicle

FYI, this program requires a raspberry pi along with the car frame and relavant components to operate. These components include cameras, IR sensors and motors along with the battery pack to supply power once disconnected from the ethernet cable used to supply power. 

- In order to upload your code to the robot, you will have to ssh to the network drive of the robot i.e. ssh esd204@10.0.1.2:(specify directory if one has already been made) 

- You will also have to create a makefile(executable)

- You can then run the file using the command 'make -n run' as long as you are within the same directory as the makefile. 

The intended behaviour of the robot car is as follows: 
1.	If a red circle (blob) is detected, calculate distance from the robot and the blob. 
2.	If there is no red circle detected within the local vicinity of the cameras (defined by macros specified at the start of the code), then turn right in order for the cameras to detect a change in its surroundings i.e., the red blob is placed in front of the robot car. 
3.	In the event a red circle is detected, the robot car will move forward and follow the blob given the blob remains a certain distance away from the cameras and falls within the horizontal axis defined. 
4.	If the blob is detected but is not within the specified horizontal range for alignment, then the robot car will repeatedly turn left or right to adjust itself before moving forward to follow the red blob. 
5.	If we stop the blob from remaining the distance defined to cause the car to move forward, when we place the blob a given distance away from the robot and the blob is in range of the horizontal axis specified, it will reverse. 
6.	The same reasoning applies for when the car stops as a result of the blob being placed a given distance from the robot. In this instance, the car is attempting to avoid the object placed in front of it.

We first specify distance thresholds defined as macros that will be used within conditions to compare whether the distance calculated using the initio_UsGetDistance() function is less than the minimum distance and greater than the maximum distance. In our case, it ranges between 45cm being the minimum and 90cm being the maximum distance.

We then define the data structure ‘thread_dat’ which will be used to communicate with the main thread and that of the camera. The threads are used so that we can run the blob thread which is used for visual sensing and searching for the blob alongside the main program simultaneously. 

The first section of code with the purpose to perform an action is that labelled under ‘object avoidance’. In this section, in the instance one of the IR sensors detects an object in front of it i.e. initio_IrLeft() !=0, initio_IrRight()!=0, an output will be displayed showing the values detected by the left and right IR sensors stating that its state is ‘OA’ (Object Avoidance). We then clear this output using ‘clrtoeol()’ function to erase the current line from the cursor. As this section is encapsulated within a while loop, this process will happen recursively thus the output on the screen will change in accordance with the real time readings being received by the IR sensors. The robot car will then stop through the use of ‘intio_DriveForward(0);’. If the IR sensors do need receive a change in value, we run the ‘refresh ()’ so that we can update the display to output the results of the next process ahead which will be to search for a blob. 

In order for the main program to run alongside the camera thread, we first implement the use of a mutex lock so that we can update the blob variable atomically to copy the blob value stored within the camera thread structure over to the variable blob within the main program where ‘ptdat’ points to the memory location of the thread, then uses the ‘->’ operator to access the blob value stored within the ‘struct thread_dat’. Here, we have to consider the ‘race condition’ where the order of execution of the program makes a big difference in processing time. And in our case, we want the robot car to respond to the given change in its environment as quickly as possible. We establish a critical section in the code where we use the same data across multiple threads/processes i.e., the blob object from the camera thread. The use of the mutex primitives pthread_mutex_lock/unlock will ensure mutual exclusion of any other threads running the section of code between the mutex primitives. If the cameras were to detect a red blob spontaneously, we would have to take into consideration what values are being accessed at the given moment in time where both threads are running concurrently. Thus, if the main program is accessing the blob, but the blob thread is also updating the blob variable within the structure, then there will be concurrency issues. Therefore we use synchronisation to determine where the threads are in respects to the flow of their executions, thus, we access the blob object from the struct before we use the value within any further conditions further down the code i.e., blob.size > 20 within the main thread. 

After the mutex lock/unlock, if the blob size is not sufficient, then an output will be displayed showing that the robot car is in a state of searching for the blob (State SB) with all associated values present. Once again, we use the ‘clrtoeol()’ function to erase the current line from the cursor. We then compare ‘blobnr’ against ‘blobnr’ within the camera thread. The first time this code is executed, ‘blobnr’ from the main program will always be less than ‘blobnr’ from the camera thread. Thus, the robot will spin right for 200 milliseconds before it stops again and then reinitialises ‘blobnr’ from the main program with the value of ‘blobnr’ from the camera thread. This process will continue recursively unless the blob size is sufficient in which case, if ‘carBlobAligned’ is within the horizontal range specified, the robot car will calculate the distance from the robot car using the intio_UsGetDistance() function and based of its reading will determine which switch case will be activated i.e. drive forward, reverse, stop.

If the blob size is sufficient, but is not aligned, then the output on the screen will change showing that the state is aligning towards the blob (State AB) with all associated values present. As per usual the ‘clrtoeol()’ function is used again where immediately after, the ‘blobnr’ from the main program is compared against that within camera thread. If the last movement is greater than the most recent movement of the blob, then based on the horizontal alignment of the blob in relation to camera will determine whether the robot car will spin left or right. This action will repeat until the robot is aligned with the bot.   

